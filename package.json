{
  "name": "fast-topic-analysis",
  "version": "1.0.1",
  "description": "Semantically create chunks from large texts. Useful for workflows involving large language models (LLMs).",
  "repository": {
    "type": "git",
    "url": "https://github.com/jparkerweb/fast-topic-analysis.git"
  },
  "bugs": {
    "url": "https://github.com/jparkerweb/fast-topic-analysis/issues",
    "email": "equilllabs@gmail.com"
  },
  "main": "index.js",
  "type": "module",
  "scripts": {
    "start": "node run-test.js",
    "generate": "node generate.js"
  },
  "keywords": [
    "nlp",
    "embeddings",
    "text-analysis",
    "machine-learning",
    "topic-detection",
    "semantic-analysis",
    "text-classification",
    "natural-language-processing",
    "huggingface",
    "transformers",
    "onnx",
    "text-similarity",
    "document-classification",
    "content-filtering",
    "text-processing"
  ],
  "author": "jparkerweb@gmail.com",
  "license": "ISC",
  "dependencies": {
    "@huggingface/transformers": "^3.2.0",
    "@stdlib/nlp-sentencize": "^0.2.2",
    "chalk": "^5.3.0",
    "dotenv": "^16.4.7"
  }
}
